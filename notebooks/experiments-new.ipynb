{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate evals for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nas/ucb/dfeng/anaconda3/envs/reward_uncertainty/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from reward_uncertainty.model.simple_preference_model import SimplePreferenceModel\n",
    "from reward_uncertainty.store.disk_store import DiskBackingStore\n",
    "\n",
    "ROOT = \"/nas/ucb/dfeng\"\n",
    "\n",
    "model_list = os.listdir(os.path.join(ROOT, \"blobs\"))\n",
    "simple_pref_models: list[SimplePreferenceModel] = []\n",
    "\n",
    "for model_id in model_list:\n",
    "    if \"simple_\" not in model_id:\n",
    "        continue\n",
    "    \n",
    "    store = DiskBackingStore.get(model_id)\n",
    "    assert store is not None\n",
    "\n",
    "    model = SimplePreferenceModel.from_backing_store(store)\n",
    "    if model.config.ensemble_id is not None:\n",
    "        continue\n",
    "\n",
    "    simple_pref_models.append(model)\n",
    "\n",
    "len(simple_pref_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from reward_uncertainty.model.ensemble.simple_ensemble import SimplePreferenceModelEnsemble\n",
    "\n",
    "ensemble_pref_models: list[SimplePreferenceModelEnsemble] = []\n",
    "for model_id in model_list:\n",
    "    if \"ensemble_\" not in model_id:\n",
    "        continue\n",
    "\n",
    "    store = DiskBackingStore.get(model_id)\n",
    "    assert store is not None\n",
    "\n",
    "    model = SimplePreferenceModelEnsemble.from_backing_store(store)\n",
    "    ensemble_pref_models.append(model)\n",
    "\n",
    "len(ensemble_pref_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments.extras.slurm import JobConfig, RemoteExperiment, run_remote_experiment\n",
    "from reward_uncertainty.eval.reward_eval import RewardEval\n",
    "\n",
    "\n",
    "def run_evals(model: SimplePreferenceModel, dry_run: bool = False):\n",
    "    evals = set([\n",
    "        \"hh_rlhf_helpful\",\n",
    "        \"hh_rlhf_jailbroken\",\n",
    "        \"strongreject_jailbroken\",\n",
    "        \"safe_rlhf\"\n",
    "    ])\n",
    "\n",
    "    alr_run_evals = set()\n",
    "    for eval in model.evals:\n",
    "        if isinstance(eval, RewardEval):\n",
    "            alr_run_evals.add(eval.config.dataset_name)\n",
    "\n",
    "    evals = evals - alr_run_evals\n",
    "    print(f\"Model:{model.id}, Evals:{evals}\")\n",
    "    for eval_name in evals:        \n",
    "        run_remote_experiment(\n",
    "            RemoteExperiment.EVALUATE_REWARD_MODEL, \n",
    "            JobConfig(args={\n",
    "                \"reward_model_id\": model.id,\n",
    "                \"dataset\": eval_name,\n",
    "                \"batch_size\": \"16\",\n",
    "                \"max_length\": \"512\",\n",
    "            }),\n",
    "            dry_run=dry_run\n",
    "        )\n",
    "\n",
    "\n",
    "def run_ensemble_evals(model: SimplePreferenceModelEnsemble, dry_run: bool = False):\n",
    "    evals = set([\n",
    "        \"hh_rlhf_helpful\",\n",
    "        \"hh_rlhf_jailbroken\",\n",
    "        \"strongreject_jailbroken\",\n",
    "        \"safe_rlhf\"\n",
    "    ])\n",
    "\n",
    "    alr_run_evals = set()\n",
    "    for eval in model.evals:\n",
    "        if isinstance(eval, RewardEval):\n",
    "            alr_run_evals.add(eval.config.dataset_name)\n",
    "\n",
    "    evals = evals - alr_run_evals\n",
    "    print(f\"Model:{model.id}, Evals:{evals}\")\n",
    "    for eval_name in evals:        \n",
    "        run_remote_experiment(\n",
    "            RemoteExperiment.EVALUATE_ENSEMBLE_REWARD_MODEL, \n",
    "            JobConfig(args={\n",
    "                \"ensemble_model_id\": model.id,\n",
    "                \"dataset\": eval_name,\n",
    "                \"batch_size\": \"16\",\n",
    "                \"max_length\": \"512\",\n",
    "            }),\n",
    "            dry_run=dry_run\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:20250331-112939_simple__adcc6b21-b1a9-4e64-9465-803ab4af0739, Evals:set()\n",
      "Model:20250331-112924_simple__ff744888-ce90-4552-b3fa-e9e434613398, Evals:set()\n",
      "Model:20250331-112919_simple__86e11b19-99f5-4034-a6b3-9316e0ad821f, Evals:set()\n",
      "Model:20250331-112940_simple__893d99b2-4b25-437a-9c1f-d5783feae27d, Evals:set()\n",
      "Model:20250331-112918_simple__bd18d6f0-7d44-4cbf-a8e9-888adc39f019, Evals:set()\n",
      "Model:20250331-112927_simple__63156b72-d3b4-491a-831c-d745d3bc8dd5, Evals:set()\n",
      "Model:20250331-112922_simple__bfadce2a-2cce-4c52-a1c7-e587a19083e3, Evals:set()\n",
      "Model:20250331-112929_simple__360d8bd8-224a-47ba-a21b-a80c5ad1dfe7, Evals:set()\n",
      "Model:20250331-112925_simple__91697818-d303-45ad-a613-e5acb742539b, Evals:set()\n",
      "Model:20250331-112932_simple__ed9e434d-7988-4ddc-be40-fff5d5575e0a, Evals:set()\n",
      "Model:20250331-112937_simple__9f493caa-65e6-4964-bcc2-35adb121b6f2, Evals:set()\n",
      "Model:20250331-112928_simple__81d9827a-60aa-418e-b205-0af0953a7949, Evals:set()\n",
      "Model:20250331-112921_simple__35c69356-481a-4f9a-a746-58c8f4037cab, Evals:set()\n",
      "Model:20250331-113315_simple__3c4efcc4-1911-43b9-8eb6-2bbf69db2a85, Evals:set()\n",
      "Model:20250331-112934_simple__62a2ad8a-ed61-4e4f-8dab-46a61fce2485, Evals:set()\n",
      "Model:20250331-112917_simple__8016f451-953a-489a-ad59-e8512f26bfc5, Evals:set()\n"
     ]
    }
   ],
   "source": [
    "for model in simple_pref_models:\n",
    "    run_evals(model, dry_run=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:20250331-133452_ensemble__99235489-4541-4fcd-bbd2-84badd744bb8, Evals:set()\n",
      "Model:20250331-132441_ensemble__7052ee53-c29c-45f8-86b8-074142ff7308, Evals:set()\n",
      "Model:20250331-133253_ensemble__7fcf04e7-4991-4438-b449-add1a3b86839, Evals:set()\n",
      "Model:20250331-133446_ensemble__2c889e44-d1c4-4f01-8b4f-aa3324d1c286, Evals:set()\n",
      "Model:20250331-133321_ensemble__9052df98-f238-47c4-bbb4-9ca94ba2089e, Evals:set()\n",
      "Model:20250331-133504_ensemble__e2993768-1d20-41a7-a586-d9dd7df0e9d8, Evals:set()\n",
      "Model:20250331-133400_ensemble__2b7b6994-eb2f-46c3-9fb9-246b1da1c3a8, Evals:set()\n",
      "Model:20250331-133249_ensemble__f7a157e2-279d-4382-9e85-b3f1819b2aa4, Evals:set()\n",
      "Model:20250331-133403_ensemble__8146b904-06d8-471d-b0af-cafb9e09313f, Evals:set()\n",
      "Model:20250331-133533_ensemble__9acd9a00-1454-40a2-9913-a5b012e20f9f, Evals:set()\n",
      "Model:20250331-133405_ensemble__52d168e6-b751-4fec-a90a-ae77216e1666, Evals:set()\n",
      "Model:20250331-133405_ensemble__14cddb02-1dee-4ed5-ab2b-57582c181298, Evals:set()\n",
      "Model:20250331-133415_ensemble__2cd55e87-76e0-4820-aabd-1767af4c91eb, Evals:set()\n",
      "Model:20250331-133407_ensemble__093d877d-a0e3-42a0-8378-72c6d40eca34, Evals:set()\n",
      "Model:20250331-133431_ensemble__79e57510-5eb4-4544-ae6d-b24eb0fd5843, Evals:set()\n",
      "Model:20250331-133421_ensemble__1f476559-5fb2-4954-8696-6db4b7368162, Evals:set()\n",
      "Model:20250331-133455_ensemble__cdff17fc-af82-4be6-a1ef-cf07ecec6558, Evals:set()\n",
      "Model:20250331-133318_ensemble__e08ce1bf-161b-4ded-a5a4-238e22fb471e, Evals:set()\n",
      "Model:20250331-133311_ensemble__806cd7fa-36a5-4c97-b8c8-54914b90960a, Evals:set()\n",
      "Model:20250331-133408_ensemble__aa9a2052-9ab0-4657-88d7-2900860d9ef4, Evals:set()\n",
      "Model:20250331-133459_ensemble__e5b1950a-7b62-4f8f-b3e8-e464fd7b68fd, Evals:set()\n",
      "Model:20250331-133301_ensemble__b49dbbca-493d-4c77-97a6-00304570ee12, Evals:set()\n",
      "Model:20250331-133531_ensemble__6b815fb8-ba4b-404e-8be4-9953160e6950, Evals:set()\n",
      "Model:20250331-133422_ensemble__fa0a5e0f-0dda-4868-b456-e1f472688e10, Evals:set()\n",
      "Model:20250331-133304_ensemble__8940f11c-da48-404c-a358-8ae197248dd2, Evals:set()\n",
      "Model:20250331-133527_ensemble__9e13ba55-c6c3-4fd2-a0ec-6cd865010c36, Evals:set()\n",
      "Model:20250331-133519_ensemble__875690e6-584b-4e8d-9454-7e099fbd2328, Evals:set()\n",
      "Model:20250331-133356_ensemble__ecdf404d-b8e4-4367-8a6a-7bdc30dba156, Evals:set()\n",
      "Model:20250331-133420_ensemble__fbb5660b-960c-4f75-86bf-7c085934a943, Evals:set()\n",
      "Model:20250331-133254_ensemble__fc231bb6-7223-4927-b548-89937edda27f, Evals:set()\n",
      "Model:20250331-133352_ensemble__76000806-7d17-4914-bbe7-98ed71b96408, Evals:set()\n",
      "Model:20250331-133233_ensemble__a0aa8bb8-f120-4fea-a861-2d6adf3a694b, Evals:set()\n",
      "Model:20250331-133420_ensemble__8be624f8-290d-4e75-b290-a436814e72f7, Evals:set()\n",
      "Model:20250331-133401_ensemble__1c4c4f29-ab52-4ee4-b019-166f47f1e37a, Evals:set()\n",
      "Model:20250331-133458_ensemble__5b44cbcb-6ed3-4c04-9111-853b77afba97, Evals:set()\n",
      "Model:20250331-133340_ensemble__f7e5e50d-fd69-49d0-a5ed-fe5c6f8b674d, Evals:set()\n",
      "Model:20250331-133404_ensemble__2f402c33-8517-49a2-98b2-cdc26a3697de, Evals:set()\n",
      "Model:20250331-133441_ensemble__489fc745-d0d3-43e8-b1bc-6f27e68eac26, Evals:set()\n",
      "Model:20250331-133411_ensemble__ca56ae3a-20b7-4ae8-8502-68d48f07edba, Evals:set()\n",
      "Model:20250331-133510_ensemble__7571a291-bca0-4879-b6eb-09926e876fba, Evals:set()\n",
      "Model:20250331-133523_ensemble__78f97efe-b7b8-4eb6-8eb6-3de2113fd05d, Evals:set()\n",
      "Model:20250331-133418_ensemble__634ad4f4-5c09-40c1-853b-cfdaf75d08b4, Evals:set()\n",
      "Model:20250331-133333_ensemble__fa3742e7-2111-491f-97b0-336f497ae801, Evals:set()\n",
      "Model:20250331-133450_ensemble__5d1f1cf6-ab0d-4cf4-b360-33f1aca7c4c1, Evals:set()\n"
     ]
    }
   ],
   "source": [
    "for model in ensemble_pref_models:\n",
    "    run_ensemble_evals(model, dry_run=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get scores for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_dataset</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>num_train_epochs</th>\n",
       "      <th>lora_alpha</th>\n",
       "      <th>lora_dropout</th>\n",
       "      <th>lora_rank</th>\n",
       "      <th>train_batch_size</th>\n",
       "      <th>eval_id</th>\n",
       "      <th>eval_type</th>\n",
       "      <th>brier_score</th>\n",
       "      <th>auroc_score</th>\n",
       "      <th>rmsce_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20250331-112939_simple__adcc6b21-b1a9-4e64-946...</td>\n",
       "      <td>google/gemma-2b</td>\n",
       "      <td>hh_rlhf_helpful</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>0.1</td>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "      <td>20250402-065916_reward_eval__d0baeb23-f632-4d5...</td>\n",
       "      <td>hh_rlhf_helpful</td>\n",
       "      <td>0.355449</td>\n",
       "      <td>0.810687</td>\n",
       "      <td>0.036848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20250331-112939_simple__adcc6b21-b1a9-4e64-946...</td>\n",
       "      <td>google/gemma-2b</td>\n",
       "      <td>hh_rlhf_helpful</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>0.1</td>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "      <td>20250405-095646_reward_eval__6a453fea-da84-468...</td>\n",
       "      <td>safe_rlhf</td>\n",
       "      <td>0.742456</td>\n",
       "      <td>0.278031</td>\n",
       "      <td>0.401182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20250331-112939_simple__adcc6b21-b1a9-4e64-946...</td>\n",
       "      <td>google/gemma-2b</td>\n",
       "      <td>hh_rlhf_helpful</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>0.1</td>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "      <td>20250410-204341_reward_eval__84f1f1b6-a474-432...</td>\n",
       "      <td>strongreject_jailbroken</td>\n",
       "      <td>1.806448</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>0.950373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20250331-112939_simple__adcc6b21-b1a9-4e64-946...</td>\n",
       "      <td>google/gemma-2b</td>\n",
       "      <td>hh_rlhf_helpful</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>0.1</td>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "      <td>20250410-204341_reward_eval__5c805013-56ab-4db...</td>\n",
       "      <td>hh_rlhf_jailbroken</td>\n",
       "      <td>1.365752</td>\n",
       "      <td>0.042356</td>\n",
       "      <td>0.793314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20250331-112924_simple__ff744888-ce90-4552-b3f...</td>\n",
       "      <td>google/gemma-2b</td>\n",
       "      <td>hh_rlhf_helpful</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>0.1</td>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "      <td>20250402-070458_reward_eval__fa1aaf3c-b62e-430...</td>\n",
       "      <td>hh_rlhf_helpful</td>\n",
       "      <td>0.382709</td>\n",
       "      <td>0.779894</td>\n",
       "      <td>0.038305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            model_id       model_name  \\\n",
       "0  20250331-112939_simple__adcc6b21-b1a9-4e64-946...  google/gemma-2b   \n",
       "1  20250331-112939_simple__adcc6b21-b1a9-4e64-946...  google/gemma-2b   \n",
       "2  20250331-112939_simple__adcc6b21-b1a9-4e64-946...  google/gemma-2b   \n",
       "3  20250331-112939_simple__adcc6b21-b1a9-4e64-946...  google/gemma-2b   \n",
       "4  20250331-112924_simple__ff744888-ce90-4552-b3f...  google/gemma-2b   \n",
       "\n",
       "     train_dataset  learning_rate  num_train_epochs  lora_alpha  lora_dropout  \\\n",
       "0  hh_rlhf_helpful        0.00002                 2         128           0.1   \n",
       "1  hh_rlhf_helpful        0.00002                 2         128           0.1   \n",
       "2  hh_rlhf_helpful        0.00002                 2         128           0.1   \n",
       "3  hh_rlhf_helpful        0.00002                 2         128           0.1   \n",
       "4  hh_rlhf_helpful        0.00001                 1         128           0.1   \n",
       "\n",
       "   lora_rank  train_batch_size  \\\n",
       "0         64                16   \n",
       "1         64                16   \n",
       "2         64                16   \n",
       "3         64                16   \n",
       "4         64                16   \n",
       "\n",
       "                                             eval_id                eval_type  \\\n",
       "0  20250402-065916_reward_eval__d0baeb23-f632-4d5...          hh_rlhf_helpful   \n",
       "1  20250405-095646_reward_eval__6a453fea-da84-468...                safe_rlhf   \n",
       "2  20250410-204341_reward_eval__84f1f1b6-a474-432...  strongreject_jailbroken   \n",
       "3  20250410-204341_reward_eval__5c805013-56ab-4db...       hh_rlhf_jailbroken   \n",
       "4  20250402-070458_reward_eval__fa1aaf3c-b62e-430...          hh_rlhf_helpful   \n",
       "\n",
       "   brier_score  auroc_score  rmsce_score  \n",
       "0     0.355449     0.810687     0.036848  \n",
       "1     0.742456     0.278031     0.401182  \n",
       "2     1.806448     0.000517     0.950373  \n",
       "3     1.365752     0.042356     0.793314  \n",
       "4     0.382709     0.779894     0.038305  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from reward_uncertainty.scoring.brier_score import BrierScore\n",
    "from reward_uncertainty.scoring.rmsce_score import RMSCEScore\n",
    "from reward_uncertainty.scoring.auroc_score import AUROCScore\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
    "    return e_x / np.sum(e_x, axis=-1, keepdims=True)\n",
    "\n",
    "\n",
    "data = []\n",
    "for model in simple_pref_models:\n",
    "    evals = [e for e in model.evals if isinstance(e, RewardEval)]\n",
    "    for eval in evals:\n",
    "        results = eval.results\n",
    "        assert results is not None\n",
    "\n",
    "        results_ds = results.reward_outputs\n",
    "        reward_logits = np.array([results_ds[\"reward_output_chosen\"], results_ds[\"reward_output_rejected\"]]).transpose()\n",
    "        probs = softmax(reward_logits)\n",
    "        \n",
    "        brier_score = BrierScore().batch(probs, np.array([0 for _ in range(len(probs))]))\n",
    "        auroc_score = AUROCScore().batch(probs, np.array([0 for _ in range(len(probs))]))\n",
    "        rmsce_score = RMSCEScore(num_bins=50).batch(probs, np.array([0 for _ in range(len(probs))]))\n",
    "        data.append({\n",
    "            \"model_id\": model.id,\n",
    "            \"model_name\": model.config.model_name,\n",
    "            \"train_dataset\": model.config.train_dataset_name,\n",
    "            \"learning_rate\": model.config.learning_rate,\n",
    "            \"num_train_epochs\": model.config.num_train_epochs,\n",
    "            \"lora_alpha\": model.config.lora_alpha,\n",
    "            \"lora_dropout\": model.config.lora_dropout,\n",
    "            \"lora_rank\": model.config.lora_rank,\n",
    "            \"train_batch_size\": model.config.per_device_train_batch_size,\n",
    "            \"eval_id\": eval.id,\n",
    "            \"eval_type\": eval.config.dataset_name,\n",
    "            \"brier_score\": brier_score,\n",
    "            \"auroc_score\": auroc_score,\n",
    "            \"rmsce_score\": rmsce_score\n",
    "        })\n",
    "\n",
    "simple_pref_models_df = pd.DataFrame(data)\n",
    "simple_pref_models_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_simple_helpful = simple_pref_models_df[simple_pref_models_df[\"eval_type\"] != \"hh_rlhf_helpful\"]\n",
    "remove_simple_helpful_trained_both = remove_simple_helpful[remove_simple_helpful[\"train_dataset\"] == \"hh_rlhf_both\"]\n",
    "remove_simple_helpful_trained_helpful = remove_simple_helpful[remove_simple_helpful[\"train_dataset\"] == \"hh_rlhf_helpful\"]\n",
    "\n",
    "remove_simple_helpful_trained_both.to_csv(\"remove_simple_helpful_trained_both.csv\", index=False)\n",
    "remove_simple_helpful_trained_helpful.to_csv(\"remove_simple_helpful_trained_helpful.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Config' object has no attribute 'num_members'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m rejected_logits = np.array([results_ds[\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mreward_output_rejected_model_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(ensemble_model.config.member_ids))])\n\u001b[32m     12\u001b[39m probs = softmax(np.array([chosen_logits.flatten(), rejected_logits.flatten()]).transpose())\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m probs = probs.reshape(\u001b[38;5;28mlen\u001b[39m(probs) // \u001b[43mensemble_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnum_members\u001b[49m, \u001b[32m2\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(probs)\n\u001b[32m     17\u001b[39m brier_score = BrierScore().batch(probs, np.array([\u001b[32m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(probs))]))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/nas/ucb/dfeng/anaconda3/envs/reward_uncertainty/lib/python3.12/site-packages/pydantic/main.py:892\u001b[39m, in \u001b[36mBaseModel.__getattr__\u001b[39m\u001b[34m(self, item)\u001b[39m\n\u001b[32m    889\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[32m    890\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    891\u001b[39m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m892\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'Config' object has no attribute 'num_members'"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for ensemble_model in ensemble_pref_models:\n",
    "    evals = [e for e in ensemble_model.evals if isinstance(e, RewardEval)]\n",
    "    num_members = len(ensemble_model.config.member_ids)\n",
    "    for eval in evals:\n",
    "        results = eval.results\n",
    "        assert results is not None\n",
    "\n",
    "        results_ds = results.reward_outputs\n",
    "        chosen_logits = np.array([results_ds[f\"reward_output_chosen_model_{i}\"] for i in range(num_members)])\n",
    "        rejected_logits = np.array([results_ds[f\"reward_output_rejected_model_{i}\"] for i in range(num_members)])\n",
    "        \n",
    "        probs = softmax(np.array([chosen_logits.flatten(), rejected_logits.flatten()]).transpose())\n",
    "        probs = probs.reshape(len(probs) // num_members, 2)\n",
    "\n",
    "        print(probs)\n",
    "        \n",
    "        brier_score = BrierScore().batch(probs, np.array([0 for _ in range(len(probs))]))\n",
    "        auroc_score = AUROCScore().batch(probs, np.array([0 for _ in range(len(probs))]))\n",
    "        rmsce_score = RMSCEScore(num_bins=50).batch(probs, np.array([0 for _ in range(len(probs))]))\n",
    "\n",
    "        members = ensemble_model.members\n",
    "        data.append({\n",
    "            \"model_id\": ensemble_model.id,\n",
    "            \"model_name\": members[0].config.model_name,\n",
    "            \"num_members\": len(members),\n",
    "            \"train_dataset\": members[0].config.train_dataset_name,\n",
    "            \"learning_rate\": \", \".join([str(m.config.learning_rate) for m in members]),\n",
    "            \"num_train_epochs\": \", \".join([str(m.config.num_train_epochs) for m in members]),\n",
    "            \"lora_alpha\": \", \".join([str(m.config.lora_alpha) for m in members]),\n",
    "            \"lora_dropout\": \", \".join([str(m.config.lora_dropout) for m in members]),\n",
    "            \"lora_rank\": \", \".join([str(m.config.lora_rank) for m in members]),\n",
    "            \"train_batch_size\": \", \".join([str(m.config.per_device_train_batch_size) for m in members]),\n",
    "            \"eval_id\": eval.id,\n",
    "            \"eval_type\": eval.config.dataset_name,\n",
    "            \"brier_score\": brier_score,\n",
    "            \"auroc_score\": auroc_score,\n",
    "            \"rmsce_score\": rmsce_score\n",
    "        })\n",
    "\n",
    "        break\n",
    "\n",
    "ensemble_pref_models_df = pd.DataFrame(data)\n",
    "ensemble_pref_models_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_five_members, ensemble_two_members = ensemble_pref_models_df[ensemble_pref_models_df[\"num_members\"] == 5], ensemble_pref_models_df[ensemble_pref_models_df[\"num_members\"] == 2]\n",
    "\n",
    "ensemble_five_members_remove_helpful = ensemble_five_members[ensemble_five_members[\"eval_type\"] != \"hh_rlhf_helpful\"]\n",
    "five_trained_both = ensemble_five_members_remove_helpful[ensemble_five_members_remove_helpful[\"train_dataset\"] == \"hh_rlhf_both\"]\n",
    "five_trained_helpful = ensemble_five_members_remove_helpful[ensemble_five_members_remove_helpful[\"train_dataset\"] == \"hh_rlhf_helpful\"]\n",
    "\n",
    "five_trained_both.to_csv(\"five_trained_both.csv\", index=False)\n",
    "five_trained_helpful.to_csv(\"five_trained_helpful.csv\", index=False)\n",
    "\n",
    "ensemble_two_members_remove_helpful = ensemble_two_members[ensemble_two_members[\"eval_type\"] != \"hh_rlhf_helpful\"]\n",
    "two_trained_both = ensemble_two_members_remove_helpful[ensemble_two_members_remove_helpful[\"train_dataset\"] == \"hh_rlhf_both\"]\n",
    "two_trained_helpful = ensemble_two_members_remove_helpful[ensemble_two_members_remove_helpful[\"train_dataset\"] == \"hh_rlhf_helpful\"]\n",
    "\n",
    "two_trained_both.to_csv(\"two_trained_both.csv\", index=False)\n",
    "two_trained_helpful.to_csv(\"two_trained_helpful.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete evals (if necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_eval_names = [\n",
    "    \"hh_rlhf_jailbroken\",\n",
    "    \"strongreject_jailbroken\",\n",
    "]\n",
    "\n",
    "for model in simple_pref_models:\n",
    "    rm_evals = [e for e in model.evals if isinstance(e, RewardEval) and e.config.dataset_name in rm_eval_names]\n",
    "    for rm_eval in rm_evals:\n",
    "        print(\"Removing eval\", rm_eval.id)\n",
    "        # model.remove_eval(rm_eval.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing eval 20250402-071608_reward_eval__bd3933c6-28ce-4b36-bd61-3030ba777a11\n",
      "Removing eval 20250402-071608_reward_eval__76ff3a38-e0b5-4abb-9000-bcf08bacb590\n",
      "Removing eval 20250402-072250_reward_eval__d95b2616-d14a-45f5-ac8e-069ebb311144\n",
      "Removing eval 20250402-072250_reward_eval__b06ddccf-62f1-4138-9c99-fd8015964800\n",
      "Removing eval 20250402-072250_reward_eval__5130f5e5-a049-4bf8-8955-43489d0e2b05\n",
      "Removing eval 20250402-072250_reward_eval__d43524ca-6abf-4a04-8518-dc2c87150037\n",
      "Removing eval 20250402-072249_reward_eval__107ca122-2fb7-4dc3-85c5-1407f0cb87ce\n",
      "Removing eval 20250402-072338_reward_eval__04956e9d-9957-4268-9200-e09377e82756\n",
      "Removing eval 20250402-072338_reward_eval__09f1aa0d-2460-4f38-ae51-f2430c0639b3\n",
      "Removing eval 20250402-072341_reward_eval__939656b9-ebf4-4cdc-9bf8-a251c7a0a467\n",
      "Removing eval 20250402-072456_reward_eval__4d734671-80c7-4dc2-8f6a-7b308937f54e\n",
      "Removing eval 20250402-072459_reward_eval__1589d3f7-68e8-44d6-8423-dce7e11dbb98\n",
      "Removing eval 20250402-072524_reward_eval__30715aac-816b-4728-a7fa-d5b007ee5104\n",
      "Removing eval 20250402-072526_reward_eval__5c3391e7-e766-4362-a35f-b1b590f52efd\n",
      "Removing eval 20250402-072612_reward_eval__354d6247-18ae-4f53-86d5-cdf9ffe2e778\n",
      "Removing eval 20250402-072631_reward_eval__be49ed7f-0a10-4ae7-9479-4d709ee4a241\n",
      "Removing eval 20250402-072656_reward_eval__1fdb300f-2d85-4b3f-a178-251be5bf05d6\n",
      "Removing eval 20250402-072713_reward_eval__f15b112b-8bd9-42c8-90e0-f6f463975fc7\n",
      "Removing eval 20250402-072737_reward_eval__6df33b10-a113-4cc5-b572-1e17d3a88dbe\n",
      "Removing eval 20250402-072757_reward_eval__ea866d35-d3e5-49a0-8c25-52668a747b7d\n",
      "Removing eval 20250402-072836_reward_eval__589617f0-a341-4ce4-ac29-4ec2df39457a\n",
      "Removing eval 20250402-072845_reward_eval__2bf42860-d0d2-4b79-883d-0b11336823c8\n",
      "Removing eval 20250402-072910_reward_eval__b7c49b7d-055e-4ffb-898d-f73db5a1ce75\n",
      "Removing eval 20250402-072922_reward_eval__7ae10d20-06ca-45c2-b8e1-59197450349e\n",
      "Removing eval 20250402-072930_reward_eval__ce749c12-96cb-4755-b6fd-3c801ef71e32\n",
      "Removing eval 20250402-072933_reward_eval__4b07b150-a9e7-4fde-a999-b90a60831c2e\n",
      "Removing eval 20250402-073007_reward_eval__dbd66282-c6f6-4c11-9320-397184f71359\n",
      "Removing eval 20250402-073016_reward_eval__22e82596-5347-4cd6-b564-66fa8ba9cc14\n",
      "Removing eval 20250402-073042_reward_eval__5150ef5f-68d8-41f6-827e-dd9da3d9f0e1\n",
      "Removing eval 20250402-073050_reward_eval__231dc8dc-a963-484b-8d73-7da88c7bf48e\n",
      "Removing eval 20250402-073124_reward_eval__3f126560-1731-4eb4-a0c5-6f2e2d0f1aea\n",
      "Removing eval 20250402-073136_reward_eval__e176e373-178a-4659-975c-ba0efb3251dd\n",
      "Removing eval 20250402-073217_reward_eval__61b3c50a-f9e3-44f1-b0e1-84999d3ad2ab\n",
      "Removing eval 20250402-073215_reward_eval__6deb8468-1c38-4ef0-a1ee-faf897288032\n",
      "Removing eval 20250402-073223_reward_eval__1fb62034-02c5-48b0-ba52-a3e463e8b0f8\n",
      "Removing eval 20250402-073326_reward_eval__099a547f-40dc-4b04-89e5-5ffb489e6488\n",
      "Removing eval 20250402-073341_reward_eval__a0ded440-ee6b-4305-b516-0e245ca26d57\n",
      "Removing eval 20250402-073338_reward_eval__3688c082-4fb4-460b-8220-35e481b13105\n",
      "Removing eval 20250402-073442_reward_eval__231f5fd4-e596-4983-a83e-44a196311374\n",
      "Removing eval 20250402-073450_reward_eval__abf41975-3b97-40a9-bd34-026519290cf6\n",
      "Removing eval 20250402-073528_reward_eval__68e932e1-0327-425a-923a-c063c06bd9c3\n",
      "Removing eval 20250402-073524_reward_eval__f7715f9d-032c-4418-af96-954e618462e7\n",
      "Removing eval 20250402-073610_reward_eval__04b24b22-8497-4662-b6f1-978645079e4f\n",
      "Removing eval 20250402-073652_reward_eval__99e6e01c-e132-4ff2-8857-f5aeef41bdaa\n",
      "Removing eval 20250402-073703_reward_eval__3d67d8db-a88a-4cd3-9ebd-1248c68abf2c\n",
      "Removing eval 20250402-073723_reward_eval__45fd0723-1de8-4833-8d75-b010f50438f9\n",
      "Removing eval 20250402-073759_reward_eval__e461085b-cb5e-4735-b74c-b3b70fd06f62\n",
      "Removing eval 20250402-073808_reward_eval__0b3e4bf6-c2ca-4e6d-ac46-bf9f59dafc34\n",
      "Removing eval 20250402-073855_reward_eval__8e9248f4-c63e-4f65-a967-aa952c33daec\n",
      "Removing eval 20250402-073936_reward_eval__41376c65-f993-4c0c-8e56-f2442566e27c\n",
      "Removing eval 20250402-074012_reward_eval__df3084ee-0a34-4a3a-b07c-0a208f556af0\n",
      "Removing eval 20250402-074036_reward_eval__82b193fe-5ba1-483e-a4f7-c673fcbce6fd\n",
      "Removing eval 20250402-074053_reward_eval__9ecb806f-8f91-4da0-8ac2-9bd4735cc1b8\n",
      "Removing eval 20250402-074148_reward_eval__337bf054-92f8-4dc3-9eb0-20ff19ebc193\n",
      "Removing eval 20250402-074210_reward_eval__a7e8a871-b456-424a-a751-e5fe4b017862\n",
      "Removing eval 20250402-074232_reward_eval__aaf86658-41a3-4865-bf01-44b6875bc578\n",
      "Removing eval 20250402-074314_reward_eval__065042ce-07ed-45e9-955d-c805b8c066f5\n",
      "Removing eval 20250402-074320_reward_eval__4b3722c2-b531-4ffe-a4aa-ca5d0daf4baa\n",
      "Removing eval 20250402-074334_reward_eval__84f9551a-7b2a-4963-8271-f9ab25d5a297\n",
      "Removing eval 20250402-074358_reward_eval__5dc002df-b15b-43a8-a7ef-4fcd7a33afba\n",
      "Removing eval 20250402-074411_reward_eval__5a6d9ed2-0c56-4c95-863e-72a8fd54ca44\n",
      "Removing eval 20250402-074450_reward_eval__d03f9995-337c-4fba-8aff-bed1fabdbb47\n",
      "Removing eval 20250402-074514_reward_eval__661841d2-b144-4d38-a040-3730af0f472c\n",
      "Removing eval 20250402-074517_reward_eval__ab979c78-1c5b-42b4-950c-7b6195d44362\n",
      "Removing eval 20250402-074539_reward_eval__181980ee-5d08-4a32-9980-dedd9cf57e92\n",
      "Removing eval 20250402-074559_reward_eval__f96372a7-81bb-4383-bde5-bfc5197a5d5f\n",
      "Removing eval 20250402-074623_reward_eval__d7ca7cb4-61bf-45dc-9f73-b96db6f66c39\n",
      "Removing eval 20250402-074628_reward_eval__096c6a2a-f9c5-4dc5-95f0-1cd554df9fc6\n",
      "Removing eval 20250402-074646_reward_eval__863908d3-4d57-406a-931f-9c1ed03527a1\n",
      "Removing eval 20250402-074702_reward_eval__95583927-d4f5-45cc-bc82-d07256844ee3\n",
      "Removing eval 20250402-074712_reward_eval__982e230d-0a7b-42de-91d7-9b5988ec623e\n",
      "Removing eval 20250402-074757_reward_eval__1a49254b-de3f-4d77-acc9-043890db1020\n",
      "Removing eval 20250402-074818_reward_eval__f9996736-ec5b-41e7-904f-4fee99ea3e9d\n",
      "Removing eval 20250402-074825_reward_eval__182b2e62-9753-49f4-baa4-365954cefa2f\n",
      "Removing eval 20250402-074828_reward_eval__7a931841-aa76-4206-9882-415c5c4182bf\n",
      "Removing eval 20250402-074904_reward_eval__26389b6a-866a-4272-b6c2-e9adf17567ac\n",
      "Removing eval 20250402-074913_reward_eval__edcd7d89-42c1-49e0-ba19-a1b99661ccd8\n",
      "Removing eval 20250402-074959_reward_eval__4c4a5073-ff73-4a76-843d-45ba2541d7c3\n",
      "Removing eval 20250402-075036_reward_eval__c926bc00-f4fb-4597-ad10-d50e19b2df52\n",
      "Removing eval 20250402-075039_reward_eval__0b169afa-7ae7-4d1d-ba9a-3410b0fc17bd\n",
      "Removing eval 20250402-075116_reward_eval__e01f3dd9-d34b-4705-bd11-1e30487ed8f2\n",
      "Removing eval 20250402-075153_reward_eval__a969805f-7d1a-491e-8011-82a1a55d4924\n",
      "Removing eval 20250402-075210_reward_eval__9e6e85f6-affa-4c4c-951a-d33712dde559\n",
      "Removing eval 20250402-075222_reward_eval__dc82f36c-3f81-4391-bf7e-c9587d2ed42c\n",
      "Removing eval 20250402-075254_reward_eval__62350bb2-ff83-4ee3-9f68-6ae59ccb5608\n",
      "Removing eval 20250402-075307_reward_eval__204d466f-8f9d-412e-a99c-642c9e421cb7\n",
      "Removing eval 20250402-075412_reward_eval__677a52da-7063-4008-bad4-6cb338a587c2\n",
      "Removing eval 20250402-075418_reward_eval__8c922a8f-1fb1-4bc4-b71b-a6a293d8332a\n"
     ]
    }
   ],
   "source": [
    "for model in ensemble_pref_models:\n",
    "    rm_evals = [e for e in model.evals if isinstance(e, RewardEval) and e.config.dataset_name in rm_eval_names]\n",
    "    for rm_eval in rm_evals:\n",
    "        print(\"Removing eval\", rm_eval.id)\n",
    "        # model.remove_eval(rm_eval.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
