{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chosen</th>\n",
       "      <th>rejected</th>\n",
       "      <th>data_subset</th>\n",
       "      <th>reward_output_chosen</th>\n",
       "      <th>reward_output_rejected</th>\n",
       "      <th>hs_chosen_0</th>\n",
       "      <th>hs_chosen_1</th>\n",
       "      <th>hs_chosen_2</th>\n",
       "      <th>hs_chosen_3</th>\n",
       "      <th>hs_chosen_4</th>\n",
       "      <th>...</th>\n",
       "      <th>hs_rejected_2038</th>\n",
       "      <th>hs_rejected_2039</th>\n",
       "      <th>hs_rejected_2040</th>\n",
       "      <th>hs_rejected_2041</th>\n",
       "      <th>hs_rejected_2042</th>\n",
       "      <th>hs_rejected_2043</th>\n",
       "      <th>hs_rejected_2044</th>\n",
       "      <th>hs_rejected_2045</th>\n",
       "      <th>hs_rejected_2046</th>\n",
       "      <th>hs_rejected_2047</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\nHuman: What are some cuss words in english...</td>\n",
       "      <td>\\n\\nHuman: What are some cuss words in english...</td>\n",
       "      <td>harmless</td>\n",
       "      <td>[-1.5234375]</td>\n",
       "      <td>[0.765625]</td>\n",
       "      <td>-1.046875</td>\n",
       "      <td>2.765625</td>\n",
       "      <td>1.070312</td>\n",
       "      <td>-1.437500</td>\n",
       "      <td>-2.265625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.789062</td>\n",
       "      <td>-1.468750</td>\n",
       "      <td>0.330078</td>\n",
       "      <td>-0.089844</td>\n",
       "      <td>-0.636719</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>2.703125</td>\n",
       "      <td>0.382812</td>\n",
       "      <td>1.523438</td>\n",
       "      <td>1.265625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\nHuman: What kind of noises did dinosaurs m...</td>\n",
       "      <td>\\n\\nHuman: What kind of noises did dinosaurs m...</td>\n",
       "      <td>harmless</td>\n",
       "      <td>[-2.203125]</td>\n",
       "      <td>[-2.328125]</td>\n",
       "      <td>-1.023438</td>\n",
       "      <td>2.078125</td>\n",
       "      <td>0.324219</td>\n",
       "      <td>-1.085938</td>\n",
       "      <td>-0.589844</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.980469</td>\n",
       "      <td>-0.081543</td>\n",
       "      <td>-0.949219</td>\n",
       "      <td>-0.298828</td>\n",
       "      <td>-0.605469</td>\n",
       "      <td>-1.265625</td>\n",
       "      <td>2.625000</td>\n",
       "      <td>2.437500</td>\n",
       "      <td>0.460938</td>\n",
       "      <td>-0.283203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\nHuman: If you were going to steal from a c...</td>\n",
       "      <td>\\n\\nHuman: If you were going to steal from a c...</td>\n",
       "      <td>harmless</td>\n",
       "      <td>[-0.63671875]</td>\n",
       "      <td>[2.765625]</td>\n",
       "      <td>0.117188</td>\n",
       "      <td>2.468750</td>\n",
       "      <td>-0.131836</td>\n",
       "      <td>0.435547</td>\n",
       "      <td>-0.726562</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.312500</td>\n",
       "      <td>-0.219727</td>\n",
       "      <td>-1.429688</td>\n",
       "      <td>1.414062</td>\n",
       "      <td>1.460938</td>\n",
       "      <td>-0.578125</td>\n",
       "      <td>6.812500</td>\n",
       "      <td>0.099121</td>\n",
       "      <td>-1.414062</td>\n",
       "      <td>2.484375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n\\nHuman: Can you provide me the home address...</td>\n",
       "      <td>\\n\\nHuman: Can you provide me the home address...</td>\n",
       "      <td>harmless</td>\n",
       "      <td>[0.70703125]</td>\n",
       "      <td>[0.71875]</td>\n",
       "      <td>-0.147461</td>\n",
       "      <td>1.859375</td>\n",
       "      <td>-0.200195</td>\n",
       "      <td>1.328125</td>\n",
       "      <td>-0.527344</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.703125</td>\n",
       "      <td>0.675781</td>\n",
       "      <td>-0.871094</td>\n",
       "      <td>1.007812</td>\n",
       "      <td>-0.099121</td>\n",
       "      <td>0.251953</td>\n",
       "      <td>7.625000</td>\n",
       "      <td>3.031250</td>\n",
       "      <td>0.683594</td>\n",
       "      <td>0.726562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n\\nHuman: How do you embezzle money?\\n\\nAssis...</td>\n",
       "      <td>\\n\\nHuman: How do you embezzle money?\\n\\nAssis...</td>\n",
       "      <td>harmless</td>\n",
       "      <td>[-1.3046875]</td>\n",
       "      <td>[3.78125]</td>\n",
       "      <td>-0.300781</td>\n",
       "      <td>3.078125</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.118652</td>\n",
       "      <td>-0.804688</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.414062</td>\n",
       "      <td>-0.287109</td>\n",
       "      <td>0.882812</td>\n",
       "      <td>1.296875</td>\n",
       "      <td>1.007812</td>\n",
       "      <td>0.248047</td>\n",
       "      <td>7.187500</td>\n",
       "      <td>-0.035156</td>\n",
       "      <td>-1.367188</td>\n",
       "      <td>0.535156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86367</th>\n",
       "      <td>\\n\\nHuman: I'm planning to make cookies for Ch...</td>\n",
       "      <td>\\n\\nHuman: I'm planning to make cookies for Ch...</td>\n",
       "      <td>helpful</td>\n",
       "      <td>[-0.53125]</td>\n",
       "      <td>[-1.7109375]</td>\n",
       "      <td>-1.382812</td>\n",
       "      <td>2.796875</td>\n",
       "      <td>0.151367</td>\n",
       "      <td>-0.265625</td>\n",
       "      <td>-1.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.386719</td>\n",
       "      <td>-0.906250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.207031</td>\n",
       "      <td>-0.757812</td>\n",
       "      <td>1.523438</td>\n",
       "      <td>0.648438</td>\n",
       "      <td>0.236328</td>\n",
       "      <td>-0.388672</td>\n",
       "      <td>0.163086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86368</th>\n",
       "      <td>\\n\\nHuman: What ingredients do I need to make ...</td>\n",
       "      <td>\\n\\nHuman: What ingredients do I need to make ...</td>\n",
       "      <td>helpful</td>\n",
       "      <td>[0.02319336]</td>\n",
       "      <td>[1.609375]</td>\n",
       "      <td>-0.898438</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.546875</td>\n",
       "      <td>-0.216797</td>\n",
       "      <td>0.126953</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.640625</td>\n",
       "      <td>-0.921875</td>\n",
       "      <td>-1.054688</td>\n",
       "      <td>-0.457031</td>\n",
       "      <td>0.026245</td>\n",
       "      <td>-1.351562</td>\n",
       "      <td>7.062500</td>\n",
       "      <td>0.075684</td>\n",
       "      <td>-0.324219</td>\n",
       "      <td>0.216797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86369</th>\n",
       "      <td>\\n\\nHuman: Can you find a guide for caring for...</td>\n",
       "      <td>\\n\\nHuman: Can you find a guide for caring for...</td>\n",
       "      <td>helpful</td>\n",
       "      <td>[1.796875]</td>\n",
       "      <td>[1.203125]</td>\n",
       "      <td>-1.101562</td>\n",
       "      <td>-0.023438</td>\n",
       "      <td>1.593750</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.380859</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.984375</td>\n",
       "      <td>-1.562500</td>\n",
       "      <td>-0.443359</td>\n",
       "      <td>-1.437500</td>\n",
       "      <td>0.455078</td>\n",
       "      <td>0.215820</td>\n",
       "      <td>9.187500</td>\n",
       "      <td>-0.570312</td>\n",
       "      <td>0.988281</td>\n",
       "      <td>1.734375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86370</th>\n",
       "      <td>\\n\\nHuman: I like to host guests at my home fr...</td>\n",
       "      <td>\\n\\nHuman: I like to host guests at my home fr...</td>\n",
       "      <td>helpful</td>\n",
       "      <td>[1.0703125]</td>\n",
       "      <td>[1.8671875]</td>\n",
       "      <td>-0.472656</td>\n",
       "      <td>1.445312</td>\n",
       "      <td>0.996094</td>\n",
       "      <td>-0.445312</td>\n",
       "      <td>0.337891</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.117188</td>\n",
       "      <td>-1.109375</td>\n",
       "      <td>-0.038574</td>\n",
       "      <td>-0.412109</td>\n",
       "      <td>-0.129883</td>\n",
       "      <td>1.554688</td>\n",
       "      <td>5.468750</td>\n",
       "      <td>-0.628906</td>\n",
       "      <td>-0.324219</td>\n",
       "      <td>0.458984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86371</th>\n",
       "      <td>\\n\\nHuman: Does the US really go to war becaus...</td>\n",
       "      <td>\\n\\nHuman: Does the US really go to war becaus...</td>\n",
       "      <td>helpful</td>\n",
       "      <td>[0.36914062]</td>\n",
       "      <td>[0.09082031]</td>\n",
       "      <td>-0.605469</td>\n",
       "      <td>0.166992</td>\n",
       "      <td>-0.257812</td>\n",
       "      <td>-0.243164</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.335938</td>\n",
       "      <td>0.339844</td>\n",
       "      <td>0.102051</td>\n",
       "      <td>0.738281</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>-1.890625</td>\n",
       "      <td>-0.134766</td>\n",
       "      <td>0.160156</td>\n",
       "      <td>0.792969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86372 rows Ã— 4101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  chosen  \\\n",
       "0      \\n\\nHuman: What are some cuss words in english...   \n",
       "1      \\n\\nHuman: What kind of noises did dinosaurs m...   \n",
       "2      \\n\\nHuman: If you were going to steal from a c...   \n",
       "3      \\n\\nHuman: Can you provide me the home address...   \n",
       "4      \\n\\nHuman: How do you embezzle money?\\n\\nAssis...   \n",
       "...                                                  ...   \n",
       "86367  \\n\\nHuman: I'm planning to make cookies for Ch...   \n",
       "86368  \\n\\nHuman: What ingredients do I need to make ...   \n",
       "86369  \\n\\nHuman: Can you find a guide for caring for...   \n",
       "86370  \\n\\nHuman: I like to host guests at my home fr...   \n",
       "86371  \\n\\nHuman: Does the US really go to war becaus...   \n",
       "\n",
       "                                                rejected data_subset  \\\n",
       "0      \\n\\nHuman: What are some cuss words in english...    harmless   \n",
       "1      \\n\\nHuman: What kind of noises did dinosaurs m...    harmless   \n",
       "2      \\n\\nHuman: If you were going to steal from a c...    harmless   \n",
       "3      \\n\\nHuman: Can you provide me the home address...    harmless   \n",
       "4      \\n\\nHuman: How do you embezzle money?\\n\\nAssis...    harmless   \n",
       "...                                                  ...         ...   \n",
       "86367  \\n\\nHuman: I'm planning to make cookies for Ch...     helpful   \n",
       "86368  \\n\\nHuman: What ingredients do I need to make ...     helpful   \n",
       "86369  \\n\\nHuman: Can you find a guide for caring for...     helpful   \n",
       "86370  \\n\\nHuman: I like to host guests at my home fr...     helpful   \n",
       "86371  \\n\\nHuman: Does the US really go to war becaus...     helpful   \n",
       "\n",
       "      reward_output_chosen reward_output_rejected  hs_chosen_0  hs_chosen_1  \\\n",
       "0             [-1.5234375]             [0.765625]    -1.046875     2.765625   \n",
       "1              [-2.203125]            [-2.328125]    -1.023438     2.078125   \n",
       "2            [-0.63671875]             [2.765625]     0.117188     2.468750   \n",
       "3             [0.70703125]              [0.71875]    -0.147461     1.859375   \n",
       "4             [-1.3046875]              [3.78125]    -0.300781     3.078125   \n",
       "...                    ...                    ...          ...          ...   \n",
       "86367           [-0.53125]           [-1.7109375]    -1.382812     2.796875   \n",
       "86368         [0.02319336]             [1.609375]    -0.898438     2.000000   \n",
       "86369           [1.796875]             [1.203125]    -1.101562    -0.023438   \n",
       "86370          [1.0703125]            [1.8671875]    -0.472656     1.445312   \n",
       "86371         [0.36914062]           [0.09082031]    -0.605469     0.166992   \n",
       "\n",
       "       hs_chosen_2  hs_chosen_3  hs_chosen_4  ...  hs_rejected_2038  \\\n",
       "0         1.070312    -1.437500    -2.265625  ...          0.789062   \n",
       "1         0.324219    -1.085938    -0.589844  ...         -0.980469   \n",
       "2        -0.131836     0.435547    -0.726562  ...         -1.312500   \n",
       "3        -0.200195     1.328125    -0.527344  ...         -1.703125   \n",
       "4         0.734375     0.118652    -0.804688  ...         -1.414062   \n",
       "...            ...          ...          ...  ...               ...   \n",
       "86367     0.151367    -0.265625    -1.250000  ...         -0.386719   \n",
       "86368     0.546875    -0.216797     0.126953  ...         -1.640625   \n",
       "86369     1.593750     0.609375     0.380859  ...         -0.984375   \n",
       "86370     0.996094    -0.445312     0.337891  ...         -1.117188   \n",
       "86371    -0.257812    -0.243164    -0.750000  ...         -1.335938   \n",
       "\n",
       "       hs_rejected_2039  hs_rejected_2040  hs_rejected_2041  hs_rejected_2042  \\\n",
       "0             -1.468750          0.330078         -0.089844         -0.636719   \n",
       "1             -0.081543         -0.949219         -0.298828         -0.605469   \n",
       "2             -0.219727         -1.429688          1.414062          1.460938   \n",
       "3              0.675781         -0.871094          1.007812         -0.099121   \n",
       "4             -0.287109          0.882812          1.296875          1.007812   \n",
       "...                 ...               ...               ...               ...   \n",
       "86367         -0.906250          0.000000          0.207031         -0.757812   \n",
       "86368         -0.921875         -1.054688         -0.457031          0.026245   \n",
       "86369         -1.562500         -0.443359         -1.437500          0.455078   \n",
       "86370         -1.109375         -0.038574         -0.412109         -0.129883   \n",
       "86371          0.339844          0.102051          0.738281         -0.125000   \n",
       "\n",
       "       hs_rejected_2043  hs_rejected_2044  hs_rejected_2045  hs_rejected_2046  \\\n",
       "0              0.039062          2.703125          0.382812          1.523438   \n",
       "1             -1.265625          2.625000          2.437500          0.460938   \n",
       "2             -0.578125          6.812500          0.099121         -1.414062   \n",
       "3              0.251953          7.625000          3.031250          0.683594   \n",
       "4              0.248047          7.187500         -0.035156         -1.367188   \n",
       "...                 ...               ...               ...               ...   \n",
       "86367          1.523438          0.648438          0.236328         -0.388672   \n",
       "86368         -1.351562          7.062500          0.075684         -0.324219   \n",
       "86369          0.215820          9.187500         -0.570312          0.988281   \n",
       "86370          1.554688          5.468750         -0.628906         -0.324219   \n",
       "86371          0.625000         -1.890625         -0.134766          0.160156   \n",
       "\n",
       "       hs_rejected_2047  \n",
       "0              1.265625  \n",
       "1             -0.283203  \n",
       "2              2.484375  \n",
       "3              0.726562  \n",
       "4              0.535156  \n",
       "...                 ...  \n",
       "86367          0.163086  \n",
       "86368          0.216797  \n",
       "86369          1.734375  \n",
       "86370          0.458984  \n",
       "86371          0.792969  \n",
       "\n",
       "[86372 rows x 4101 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"results/reward_models/35/artifacts/checkpoint-8040/data/bayesian_both.jsonl\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_chosen, X_rejected = np.vstack([df[f\"hs_chosen_{i}\"] for i in range(2048)]).T, np.vstack([df[f\"hs_rejected_{i}\"] for i in range(2048)]).T\n",
    "X = X_chosen - X_rejected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_subset, od_subset = \"helpful\", \"harmless\"\n",
    "\n",
    "X_train = X[df[\"data_subset\"] == id_subset][:35000]\n",
    "X_test_id = X[df[\"data_subset\"] == id_subset][35000:]\n",
    "X_test_od = X[df[\"data_subset\"] == od_subset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.ones(X_train.shape[0] // 2)\n",
    "y = np.concatenate([y, -y], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyro.nn import PyroModule, PyroSample\n",
    "import pyro\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pyro.distributions as dist\n",
    "\n",
    "\n",
    "class BayesianLogisticRegression(PyroModule):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.linear = PyroModule[nn.Linear](in_features, out_features)\n",
    "        self.linear.weight = PyroSample(dist.Normal(0., 1.).expand([out_features, in_features]).to_event(2))\n",
    "    \n",
    "    def forward(self, x, y=None):\n",
    "        logits = self.linear(x).squeeze(-1)\n",
    "        reward_pred = torch.sigmoid(logits) \n",
    "        \n",
    "        sigma = pyro.sample(\"sigma\", dist.Uniform(0., 0.1))\n",
    "        with pyro.plate(\"data\", x.shape[0]):\n",
    "            obs = pyro.sample(\"obs\", dist.Normal(reward_pred, sigma), obs=y)\n",
    "        \n",
    "        return reward_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyro.infer.autoguide import AutoDiagonalNormal\n",
    "\n",
    "model = BayesianLogisticRegression(2048, 1)\n",
    "guide = AutoDiagonalNormal(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyro.infer import SVI, Trace_ELBO\n",
    "\n",
    "adam = pyro.optim.Adam({\"lr\":0.03})\n",
    "svi = SVI(model, guide, adam, loss=Trace_ELBO())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iteration 0001] loss: 230.3701\n",
      "[iteration 0101] loss: 76.5179\n",
      "[iteration 0201] loss: 66.2631\n",
      "[iteration 0301] loss: 62.7756\n",
      "[iteration 0401] loss: 61.1773\n",
      "[iteration 0501] loss: 59.9717\n",
      "[iteration 0601] loss: 59.1174\n",
      "[iteration 0701] loss: 58.8017\n",
      "[iteration 0801] loss: 58.1393\n",
      "[iteration 0901] loss: 57.8313\n"
     ]
    }
   ],
   "source": [
    "X_tensor, y_tensor = torch.from_numpy(X_train.astype(np.float32)), torch.from_numpy(y.astype(np.float32))\n",
    "\n",
    "pyro.clear_param_store()\n",
    "for j in range(1000):\n",
    "    # calculate the loss and take a gradient step\n",
    "    loss = svi.step(X_tensor, y_tensor)\n",
    "    if j % 100 == 0:\n",
    "        print(\"[iteration %04d] loss: %.4f\" % (j + 1, loss / len(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear.bias Parameter containing:\n",
      "tensor([-3.6655], requires_grad=True)\n",
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([-1.7380,  0.7262, -0.9219,  ..., -0.9048,  0.8568,  5.1283])\n",
      "AutoDiagonalNormal.scale tensor([0.0507, 0.0482, 0.0335,  ..., 0.0757, 0.0339, 0.0671])\n"
     ]
    }
   ],
   "source": [
    "guide.requires_grad_(False)\n",
    "\n",
    "for name, value in pyro.get_param_store().items():\n",
    "    print(name, pyro.param(name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'linear.weight': tensor([[[-1.7722,  0.6937, -0.9445,  ...,  0.8025, -0.9558,  0.8339]],\n",
       " \n",
       "         [[-1.7380,  0.7262, -0.9219,  ...,  0.8362, -0.9048,  0.8568]],\n",
       " \n",
       "         [[-1.7038,  0.7588, -0.8993,  ...,  0.8698, -0.8537,  0.8796]]]),\n",
       " 'sigma': tensor([0.0994, 0.0994, 0.0994])}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guide.quantiles([0.25, 0.5, 0.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyro.infer import Predictive\n",
    "\n",
    "\n",
    "def summary(samples):\n",
    "    site_stats = {}\n",
    "    for k, v in samples.items():\n",
    "        site_stats[k] = {\n",
    "            \"mean\": torch.mean(v, 0),\n",
    "            \"std\": torch.std(v, 0),\n",
    "        }\n",
    "    return site_stats\n",
    "\n",
    "\n",
    "predictive = Predictive(model, guide=guide, num_samples=100, return_sites=(\"linear.weight\", \"obs\", \"_RETURN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'linear.weight': {'mean': tensor([[[-1.7350,  0.7290, -0.9189,  ...,  0.8413, -0.9106,  0.8533]]]),\n",
       "  'std': tensor([[[0.0466, 0.0464, 0.0307,  ..., 0.0485, 0.0767, 0.0307]]])},\n",
       " 'obs': {'mean': tensor([-4.8372e-03,  4.4851e-03,  9.8896e-03,  3.0292e-01,  6.5879e-03,\n",
       "           9.9431e-01,  6.8301e-03,  1.1051e-02, -3.2339e-04, -1.2667e-02,\n",
       "           9.7343e-03,  1.4897e-03,  9.9532e-01,  1.0032e+00,  7.5377e-03,\n",
       "          -1.8945e-02, -6.8772e-03,  1.1002e-02,  1.8877e-04,  9.8244e-01,\n",
       "           1.6702e-02,  1.9335e-02,  9.9046e-01, -1.0576e-02,  1.0053e-02,\n",
       "           3.9560e-03, -6.4018e-03,  1.0174e+00, -1.8075e-02,  3.6619e-03,\n",
       "          -1.5954e-02,  9.9434e-01, -2.5059e-03,  4.5519e-01,  8.6786e-03,\n",
       "           3.9589e-04,  9.9379e-03, -1.5272e-02,  9.9849e-01, -1.1367e-02,\n",
       "           1.6563e-01,  9.9375e-01,  9.8624e-01, -1.1297e-02,  4.7657e-03,\n",
       "           1.6090e-02, -7.4520e-03, -8.1502e-03,  9.1549e-04,  1.2015e-03,\n",
       "          -1.6060e-02,  1.0073e+00,  9.9678e-01, -1.4122e-02, -1.0406e-03,\n",
       "           1.2509e-03, -9.4963e-04, -1.5406e-02,  1.0089e+00, -1.4954e-02,\n",
       "           1.0029e+00,  9.9929e-01,  1.5824e-02, -2.2360e-02,  4.1367e-03,\n",
       "           1.0022e+00, -2.0677e-02, -1.6496e-03, -2.2713e-03, -1.3647e-02,\n",
       "           5.2426e-03, -7.5290e-03, -8.5624e-03,  6.6034e-03,  9.7277e-03,\n",
       "          -8.1818e-03,  4.7374e-03, -3.0480e-03, -4.1978e-03, -1.3167e-02,\n",
       "           6.1911e-03,  1.0128e+00,  4.3362e-03,  2.3856e-03,  1.2736e-02,\n",
       "          -1.3991e-02,  1.8647e-03,  1.0085e+00,  1.0090e+00, -7.0234e-03,\n",
       "           9.8879e-01,  9.8977e-01, -5.9953e-04,  3.4510e-03, -3.7663e-04,\n",
       "           6.0966e-03, -3.7758e-03,  3.1696e-04,  1.0014e+00, -9.1593e-03]),\n",
       "  'std': tensor([0.0903, 0.1003, 0.0973, 0.3764, 0.0978, 0.0953, 0.0947, 0.1069, 0.0947,\n",
       "          0.0914, 0.1056, 0.0886, 0.0883, 0.0973, 0.0895, 0.0954, 0.1088, 0.1083,\n",
       "          0.1061, 0.0915, 0.0965, 0.1141, 0.0981, 0.1078, 0.0966, 0.0911, 0.0983,\n",
       "          0.0925, 0.0921, 0.1145, 0.0916, 0.1064, 0.0972, 0.2377, 0.0998, 0.0865,\n",
       "          0.1054, 0.1060, 0.0919, 0.0851, 0.2302, 0.0897, 0.1007, 0.1070, 0.0814,\n",
       "          0.0978, 0.1050, 0.1052, 0.1000, 0.1146, 0.1001, 0.0911, 0.0982, 0.0920,\n",
       "          0.0986, 0.0834, 0.0994, 0.0990, 0.0982, 0.1037, 0.1019, 0.0946, 0.0958,\n",
       "          0.0976, 0.0969, 0.1013, 0.1001, 0.0945, 0.0951, 0.0908, 0.0996, 0.1027,\n",
       "          0.0893, 0.1072, 0.1057, 0.1021, 0.1043, 0.0828, 0.0893, 0.1031, 0.1035,\n",
       "          0.0965, 0.1044, 0.1013, 0.1017, 0.1038, 0.1091, 0.0970, 0.0909, 0.1023,\n",
       "          0.0936, 0.1004, 0.0846, 0.0935, 0.0993, 0.0987, 0.1044, 0.1042, 0.0982,\n",
       "          0.0962])},\n",
       " '_RETURN': {'mean': tensor([1.9336e-38, 1.5791e-13, 5.4391e-19, 2.8593e-01, 1.6592e-11, 1.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8430e-16, 1.0913e-12,\n",
       "          1.0000e+00, 1.0000e+00, 0.0000e+00, 8.4404e-26, 5.1498e-39, 0.0000e+00,\n",
       "          2.1697e-30, 1.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "          2.5271e-37, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 5.9988e-17,\n",
       "          0.0000e+00, 1.0000e+00, 4.5068e-39, 4.5295e-01, 0.0000e+00, 1.6084e-19,\n",
       "          0.0000e+00, 0.0000e+00, 1.0000e+00, 2.8443e-22, 1.8317e-01, 9.9928e-01,\n",
       "          1.0000e+00, 0.0000e+00, 8.7685e-29, 0.0000e+00, 0.0000e+00, 1.5913e-04,\n",
       "          0.0000e+00, 3.0063e-39, 1.0872e-19, 1.0000e+00, 1.0000e+00, 2.6982e-08,\n",
       "          1.1035e-20, 4.5142e-37, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "          9.9977e-01, 1.0000e+00, 6.7897e-29, 0.0000e+00, 7.4329e-14, 1.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.0555e-26,\n",
       "          0.0000e+00, 0.0000e+00, 3.0722e-19, 1.1727e-28, 0.0000e+00, 1.6753e-37,\n",
       "          4.8228e-28, 0.0000e+00, 0.0000e+00, 1.0000e+00, 1.6955e-15, 5.9902e-36,\n",
       "          2.2664e-19, 0.0000e+00, 1.4817e-02, 1.0000e+00, 1.0000e+00, 5.5587e-40,\n",
       "          1.0000e+00, 1.0000e+00, 0.0000e+00, 9.7545e-11, 0.0000e+00, 2.7283e-28,\n",
       "          0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00]),\n",
       "  'std': tensor([8.4987e-38, 1.4292e-12, 6.9666e-19, 3.6376e-01, 1.0131e-10, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.5531e-16, 3.1154e-12,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5972e-25, 1.1164e-38, 0.0000e+00,\n",
       "          6.4936e-30, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          6.6155e-37, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.3595e-17,\n",
       "          0.0000e+00, 0.0000e+00, 1.4429e-38, 2.2329e-01, 0.0000e+00, 6.2382e-19,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0219e-21, 2.0160e-01, 8.7129e-04,\n",
       "          0.0000e+00, 0.0000e+00, 2.5763e-28, 0.0000e+00, 0.0000e+00, 4.9155e-04,\n",
       "          0.0000e+00, 1.6302e-38, 3.3223e-19, 0.0000e+00, 0.0000e+00, 1.8809e-07,\n",
       "          1.7831e-20, 1.5180e-36, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          3.2841e-04, 0.0000e+00, 2.3296e-28, 0.0000e+00, 9.4711e-14, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.4929e-26,\n",
       "          0.0000e+00, 0.0000e+00, 4.4388e-19, 3.6226e-28, 0.0000e+00, 7.9094e-37,\n",
       "          1.9044e-27, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2238e-15, 2.1277e-35,\n",
       "          5.2175e-19, 0.0000e+00, 2.1881e-02, 0.0000e+00, 0.0000e+00, 3.7411e-39,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3358e-10, 0.0000e+00, 4.8586e-28,\n",
       "          0.0000e+00, 0.0000e+00, 9.0795e-07, 0.0000e+00])}}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = predictive(torch.from_numpy(X_test_id.astype(np.float32))[:100])\n",
    "pred_summary = summary(samples)\n",
    "pred_summary\n",
    "# id_obs_mean, id_obs_std = pred_summary[\"_RETURN\"][\"mean\"].numpy(), pred_summary[\"_RETURN\"][\"std\"].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'linear.weight': {'mean': tensor([[[-1.7483,  0.7296, -0.9239,  ...,  0.8453, -0.8996,  0.8522]]]),\n",
       "  'std': tensor([[[0.0527, 0.0531, 0.0326,  ..., 0.0486, 0.0804, 0.0340]]])},\n",
       " 'obs': {'mean': tensor([ 1.0015e+00, -6.9194e-03,  9.8949e-01,  1.0014e+00,  9.9223e-01,\n",
       "           1.0098e+00, -5.1557e-03,  9.8500e-01,  9.8565e-01,  9.6730e-01,\n",
       "           1.0067e+00,  4.2940e-01,  9.9504e-03, -2.2178e-03,  1.0038e+00,\n",
       "           9.9718e-01,  1.0105e+00,  1.4772e-02, -1.2148e-02,  8.0178e-03,\n",
       "           9.8739e-01, -4.7331e-03,  2.4109e-03,  9.8774e-01,  1.2873e-02,\n",
       "           6.8138e-03, -1.4716e-02,  9.9613e-01,  9.9384e-01, -2.5590e-03,\n",
       "           1.0080e+00,  1.0078e+00, -3.9937e-03,  9.9198e-01,  9.9762e-01,\n",
       "          -9.9604e-03,  9.9482e-01,  1.0024e+00,  1.0015e+00,  1.0123e+00,\n",
       "          -6.0472e-03,  7.8730e-04,  9.8500e-01, -3.6415e-03,  1.6053e-02,\n",
       "           1.0085e+00, -1.0183e-02, -1.2972e-02,  1.0047e+00, -5.1646e-03,\n",
       "           9.8892e-01,  7.5054e-01, -9.8496e-03, -1.1127e-03,  1.0010e+00,\n",
       "           7.7853e-03,  9.8725e-01,  1.0004e+00,  9.9067e-01, -2.0490e-03,\n",
       "           1.0052e+00,  1.0067e+00,  9.9877e-01, -1.0436e-02,  1.0051e+00,\n",
       "           1.0040e+00,  1.0135e+00,  9.9651e-01,  9.9036e-01,  1.0077e+00,\n",
       "           9.9485e-01,  9.8883e-01,  1.0130e+00,  9.9378e-01,  1.0104e+00,\n",
       "           9.9739e-01,  9.8202e-01,  1.0186e+00,  2.2945e-02,  1.0078e+00,\n",
       "           9.9448e-01, -6.1914e-03,  2.4585e-02,  1.0047e+00,  9.9976e-01,\n",
       "           1.0214e+00,  1.0039e+00,  1.0028e+00,  9.9535e-01,  9.9494e-01,\n",
       "           1.0081e+00,  1.0264e-02,  9.8890e-01,  9.8940e-01, -2.9646e-03,\n",
       "           1.0065e+00,  1.0095e+00,  1.0145e+00,  9.9731e-01,  1.0083e+00]),\n",
       "  'std': tensor([0.1102, 0.0983, 0.0976, 0.0979, 0.0899, 0.1056, 0.1000, 0.1102, 0.1040,\n",
       "          0.1290, 0.1049, 0.3092, 0.0999, 0.1108, 0.1009, 0.0971, 0.0948, 0.0982,\n",
       "          0.1069, 0.1018, 0.0997, 0.0983, 0.1036, 0.1094, 0.0982, 0.1134, 0.0943,\n",
       "          0.1022, 0.1056, 0.1064, 0.1061, 0.0936, 0.0912, 0.1039, 0.1005, 0.0915,\n",
       "          0.0968, 0.1035, 0.1099, 0.1129, 0.0920, 0.0986, 0.0983, 0.0967, 0.1028,\n",
       "          0.0899, 0.0968, 0.0990, 0.0993, 0.1014, 0.1031, 0.2304, 0.1054, 0.0929,\n",
       "          0.1035, 0.0946, 0.1081, 0.0861, 0.0990, 0.1079, 0.0912, 0.0948, 0.0923,\n",
       "          0.1055, 0.1079, 0.1146, 0.0910, 0.1004, 0.0969, 0.0838, 0.0975, 0.0986,\n",
       "          0.0915, 0.1156, 0.0884, 0.1056, 0.0952, 0.0947, 0.1007, 0.0952, 0.0993,\n",
       "          0.0973, 0.1066, 0.0977, 0.0842, 0.0950, 0.0956, 0.1054, 0.0973, 0.0872,\n",
       "          0.1151, 0.1099, 0.0919, 0.0924, 0.1043, 0.0982, 0.1105, 0.0946, 0.0910,\n",
       "          0.0966])},\n",
       " '_RETURN': {'mean': tensor([1.0000e+00, 1.6059e-03, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "          7.2410e-04, 1.0000e+00, 1.0000e+00, 9.7619e-01, 1.0000e+00, 4.4445e-01,\n",
       "          0.0000e+00, 8.0758e-06, 1.0000e+00, 1.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 1.0000e+00, 1.4396e-23, 8.5113e-24, 1.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "          1.0000e+00, 1.0000e+00, 1.7591e-07, 1.0000e+00, 1.0000e+00, 2.2028e-40,\n",
       "          1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.7717e-40, 1.1465e-03,\n",
       "          1.0000e+00, 0.0000e+00, 1.8354e-38, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          1.0000e+00, 1.4087e-34, 1.0000e+00, 7.7968e-01, 8.3290e-12, 9.0523e-24,\n",
       "          1.0000e+00, 1.1378e-07, 9.7526e-01, 1.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "          1.0000e+00, 1.0000e+00, 1.0000e+00, 1.8098e-14, 1.0000e+00, 1.0000e+00,\n",
       "          1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "          1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 9.9975e-01,\n",
       "          0.0000e+00, 1.0000e+00, 1.0000e+00, 8.3040e-11, 9.0490e-16, 1.0000e+00,\n",
       "          1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "          1.0000e+00, 7.0235e-12, 1.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "          1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00]),\n",
       "  'std': tensor([0.0000e+00, 3.7515e-03, 0.0000e+00, 4.3792e-08, 0.0000e+00, 0.0000e+00,\n",
       "          1.0629e-03, 0.0000e+00, 0.0000e+00, 7.4927e-02, 0.0000e+00, 3.2856e-01,\n",
       "          0.0000e+00, 2.2252e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2418e-23, 2.9010e-23, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 4.9152e-07, 0.0000e+00, 0.0000e+00, 1.1881e-39,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7717e-39, 1.9884e-03,\n",
       "          0.0000e+00, 0.0000e+00, 3.5652e-38, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 2.3461e-34, 5.2512e-07, 2.1299e-01, 5.3286e-11, 1.8812e-23,\n",
       "          0.0000e+00, 3.0177e-07, 5.1618e-02, 1.1921e-08, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 4.7168e-14, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.0112e-04,\n",
       "          0.0000e+00, 0.0000e+00, 5.0809e-06, 6.0437e-10, 1.5528e-15, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 2.6155e-11, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00])}}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = predictive(torch.from_numpy(X_test_od.astype(np.float32))[:100])\n",
    "pred_summary_od = summary(samples)\n",
    "pred_summary_od\n",
    "# od_obs_mean, od_obs_std = pred_summary_od[\"_RETURN\"][\"mean\"].numpy(), pred_summary_od[\"_RETURN\"][\"std\"].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(\n",
    "    id_obs_mean,\n",
    "    id_obs_std,\n",
    "    alpha=0.3,\n",
    "    color=\"blue\"\n",
    ")\n",
    "\n",
    "plt.scatter(\n",
    "    od_obs_mean,\n",
    "    od_obs_std,\n",
    "    alpha=0.3,\n",
    "    color=\"red\"\n",
    ")\n",
    "\n",
    "plt.ylim(0.05, 0.2)\n",
    "plt.xlim(-10, 10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reward_uncertainty",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
